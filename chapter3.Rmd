
# Week 3: Rstudio Exercise 3- Logistic Regression

In this section we are analysing the datasets on student alcohol consumption in secondary school students in Portugal using Logistic regression.

The data from two questionnaires related to student alcohol consumption available at UCI Machine Learning Repository, [Student Alcohol consumption data page](https://archive.ics.uci.edu/ml/datasets/STUDENT+ALCOHOL+CONSUMPTION). The data consists of answers to two questionaires, one from math class and another from protugese class related to student alcohol consumption in secondary school students in Portugal.

The purpose of our analysis is to study the relationships between high/low alcohol consumption and some of the other variables in the data.

## The alc dataset
Using the program create_alc.R we joined the above two datsets to a new datset alc. The alc data set has two new columns alc_use, which is the average of weekday and weekend alcohol consumption and another column high_use which is true if alc_use > 2. This dataset is also available [here](http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/alc.txt)


### The attributes of alc dataframe


1. school - student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)
2. sex - student's sex (binary: 'F' - female or 'M' - male)
3. age - student's age (numeric: from 15 to 22)
4. address - student's home address type (binary: 'U' - urban or 'R' - rural)
5. famsize - family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3)
6. Pstatus - parent's cohabitation status (binary: 'T' - living together or 'A' - apart)
7. Medu - mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 5th to 9th grade, 3 secondary education or 4 higher education)
8. Fedu - father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 5th to 9th grade, 3 secondary education or 4 higher education)
9. Mjob - mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')
10. Fjob - father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')
11. reason - reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')
12. guardian - student's guardian (nominal: 'mother', 'father' or 'other')
13. traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)
14. studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)
15. failures - number of past class failures (numeric: n if 1<=n<3, else 4)
16. schoolsup - extra educational support (binary: yes or no)
17. famsup - family educational support (binary: yes or no)
18. paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)
19. activities - extra-curricular activities (binary: yes or no)
20. nursery - attended nursery school (binary: yes or no)
21. higher - wants to take higher education (binary: yes or no)
22. internet - Internet access at home (binary: yes or no)
23. romantic - with a romantic relationship (binary: yes or no)
24. famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)
25. freetime - free time after school (numeric: from 1 - very low to 5 - very high)
26. goout - going out with friends (numeric: from 1 - very low to 5 - very high)
27. Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)
28. Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)
29. health - current health status (numeric: from 1 - very bad to 5 - very good)
30. absences - number of school absences (numeric: from 0 to 93)
31. G1 - first period grade (numeric: from 0 to 20)
32. G2 - second period grade (numeric: from 0 to 20)
33. G3 - final grade (numeric: from 0 to 20, output target) 
34. alc_use  - average of weekday and weekend alcohol consumption
35. high_use is True if alc_use > 2

### 2. Reading the data to alc from amzonaws
```{r echo=TRUE}
alc <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/alc.txt", 
                  sep = ",", header=TRUE)
dim(alc)
summary(alc)
```

The alc dataframe has 382 observations of 35 variables. The data is collected from 2 schools in Portugal from 382 students of which 198 are females and 184 are male students. The age of the students are ranging from 15 to 22. The variable 'alc_use' is the average of weekdays and weekend alcohol consumption and "high_use" is true if alc_use > 2. 

The goal  of this analysis is to find the relationship between "high_use" which is the predictand and the other variables in the dataset alc.
We can use gather() to gather columns into key-value pairs and then glimpse() at the resulting data.
We can see the distribution of the variables by  drawing  a bar plot using ggplot.



```{r echo=TRUE, message=FALSE, warning=FALSE}
library(tidyr); library(dplyr); library(ggplot2); library(GGally)
gather(alc) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar()
```

### Variable/attribute selection according to their influence on the high/low consumption of alcohol

The next step is to select the variables/attributes based on their influence on the high/low comsumption of alcohol.


This [page](https://www.r-bloggers.com/variable-importance-plot-and-variable-selection/) says that random forests can be used to find out the importance on the variables/attributes on the predictand.

The dataset alc we have 35 variables. From the alc dataset, we removed  Dalc(workday alcohol consumption), Walc (weekend alcohol consumption), alc_use(average of weekday and weekend alcohol consumption) as the predictand high_use is calculated based on them.  We also removed the G1(first period grade) and G2(second period grade) as the final grade  G3 reflects the G1 and G2. Using randomForest package we can find  the importance of the variables.

```{r echo=TRUE, message=FALSE, warning=FALSE}
library(randomForest)
# removing the Dalc, walc, G1, G2, alc_use coulumns from alc
alc_new <- alc[-c(27,28,31,32,34)]
fit=randomForest(factor(high_use)~., data=alc_new)
(VI_F=importance(fit))
```

We can observe that the variables of importance as given by the randomForest algorithm are "goout" (going out), "absences", G3(final grade), reason (reason to choose a school), famrel(family relationship), Mjob (mother's job) and sex. Next we try to see the influence of these variables on "high_use" by plotting the graph between "high_use" and each of these variables.


First, we find how the sex influence the alcohol consumption.

```{r echo=TRUE, message=FALSE, warning=FALSE}
alc %>% group_by(sex, high_use) %>% summarise(count = n())
```

Clearly we can see that the number male students in the high_use group is more compared to female students.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# initialise a plot of high_use and gout
g2 <- ggplot(alc, aes(x = high_use, y = goout, col = sex))
# define the plot as a boxplot and draw it
g2 + geom_boxplot() + ylab("goout") + ggtitle("Student going out by alcohol consumption and sex" )
```
Among the male students, going out has a high mean value for the "high_use" group. So we select this variable

```{r echo=TRUE, message=FALSE, warning=FALSE}
# initialise a plot of high_use and absences
g2 <- ggplot(alc, aes(x = high_use, y = absences, col = sex))
# define the plot as a boxplot and draw it
g2 + geom_boxplot() + ylab("absences") + ggtitle("Student absences by alcohol consumption and sex" )
```

From the graph of Student absences by alcohol consumption and sex, "absences" have a high 75-percentile value "high_use" group. So we select this variable.
 
```{r echo=TRUE, message=FALSE, warning=FALSE}
# initialise a plot of high_use and G3
g2 <- ggplot(alc, aes(x = high_use, y = G3, col = sex))
# define the plot as a boxplot and draw it
g2 + geom_boxplot() + ylab("G3") + ggtitle("Student final grade by alcohol consumption and sex" )
```

From the Student G3(final grade) by alcohol consumption and sex graph we can observe that students with high_use of alcohol have low grades (mean and the quartile values) compared to low alcohol consumption group.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# initialise a plot of high_use and reason
g2 <- ggplot(alc, aes(x = high_use, y = reason, col = sex))
# define the plot as a boxplot and draw it
g2 + geom_boxplot() + ylab("reason") + ggtitle("Student reason to a select a school by alcohol consumption and sex" )
```


We can observe that "reason to select a school" does not have any impact on the high_use of alcohol.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# initialise a plot of high_use and Mjob
g2 <- ggplot(alc, aes(x = high_use, y = Mjob, col = sex))
# define the plot as a boxplot and draw it
g2 + geom_boxplot() + ylab("Mjob") + ggtitle("Student mother's job by alcohol consumption and sex" )
```
We can observe that the Mjob  does not have any impact on the high_use of alcohol.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# initialise a plot of high_use and failures
g2 <- ggplot(alc, aes(x = high_use, y = failures, col = sex))
# define the plot as a boxplot and draw it
g2 + geom_boxplot() + ylab("failures") + ggtitle("Student failures by alcohol consumption and sex" )
```

The above graph shows that student failures are affected by alcohol consumption for male students.

So we select the variables, "sex"", "goout", "absences", failures as the impotant variables for our analysis.
In otherwords we take predictand high_use and the explanatory variables are sex, gout, absences and failures.

### Find the model with glm() for logistic regression
```{r echo=TRUE, message=FALSE, warning=FALSE}
m <- glm(high_use ~ goout + failures + absences + sex, data = alc, family = "binomial")

# compute odds ratios (OR)
OR <- coef(m) %>% exp

# compute confidence intervals (CI)
CI <- confint(m) %>% exp

# print out the odds ratios with their confidence intervals
cbind(OR, CI)
cbind
summary(m)
```

The odds ratio OR measures the extend to which an explanatory variable influesnces the prediction of the predictand "high_use". An OR value close to 1 signifies minimal influence whereas a higher OR value indicates a large influence. So we can see from our results that 
sex and gout have higher OR values than failures and absences. 

From the confidence interval values, we observe that sexM (male) has the largest confidence interval. The difference between 25 percentile and 97.5 percentile values is around 3. The confidence interval values follows a decreasing order for goout, failures and absences.  Both OR and Confidence interval show that sex and gout influences the predictand "high_use" compared to failures and absences.

To see the significance of the categorical predictor variable sex which has two factors male and female, we do the likelyhood test.
We generate two models m1 and m2 where the model m1 includes the variable sex and model m2 does not include the variable sex.
```{r echo=TRUE, message=FALSE, warning=FALSE}
m1 <- glm(high_use ~ goout + failures + absences + sex, data = alc, family = "binomial")
m2 <- glm(high_use ~ goout + failures + absences , data = alc, family = "binomial")

anova(m1, m2, test="LRT")
```

The likelihood ratio test shows that the variable  sex is highly significant and we include it in the model.

### 6. predictive power of the model
Logistic regression gives binary predictions. The predict() function can be used to make predictions with a model object. Here we use the data alc to make the predictions for the predictand "high_use".

```{r echo=TRUE, message=FALSE, warning=FALSE}
m <- glm(high_use ~ goout + failures + absences + sex, data = alc, family = "binomial")
# predict() the probability of high_use
probabilities <- predict(m, type = "response")

# add the predicted probabilities to 'alc'
alc <- mutate(alc, probability = probabilities)

# use the probabilities to make a prediction of high_use
alc <- mutate(alc, prediction = probability > 0.5)

# tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction)

```


Actually the high_use variable for the data alc has 270 FALSE values and 112 TRUE values. We apply  logistic prediction using our model to the data alc,  the table above shows the predictions for the  variable "high_use.
When high_use is false, the prediction states it is false for 251 and wrongly predict (gives TRUE) for 19 variables. Similarly when high_use is TRUE, 62 predictions state that it is FALSE and 50 state it is TRUE.We  can see that the predictions for False values of high_use, the prediction is fairly accurate. For true values of high_use, the prediction below 50 %. We can see these results graphically.


```{r echo=TRUE, message=FALSE, warning=FALSE}
# initialize a plot of 'high_use' versus 'probability' in 'alc'
g <- ggplot(alc, aes(x = probability, y = high_use))
g +  geom_point()
# define the geom as points and draw the plot
g <- ggplot(alc, aes(x = probability, y = high_use, col = prediction))
g +  geom_point()
# tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction) %>% prop.table %>% addmargins
```

In the Datacamp exercise where we take th model with only failure, absences and sex variables we get the following prediction for high_use
```{r echo=TRUE, message=FALSE, warning=FALSE}
# fit the model
m <- glm(high_use ~ failures + absences + sex, data = alc, family = "binomial")
probabilities <- predict(m, type = "response")

# add the predicted probabilities to 'alc'
alc <- mutate(alc, probability = probabilities)

# use the probabilities to make a prediction of high_use
alc <- mutate(alc, prediction = probability > 0.5)

# tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction)
```

In the Datacamp exercise, When high_use is false, the prediction states it is false for 258 and wrongly predict (gives TRUE) for 12 variables. Similarly when high_use is TRUE,82 predictions state that it is FALSE and 26 state it is TRUE. We  can see that the predictions for False values of high_use, the prediction is fairly accurate. For true values of high_use, the predict is rather poor. 

So my model is better than Datacamp exercise model

